#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å›¾åƒå¤æ‚åº¦åˆ†æå·¥å…·ï¼ˆæµå¼å¤„ç†ç‰ˆï¼‰
åŠŸèƒ½ï¼šè®¡ç®—åˆ†å‰²å›¾åƒçš„è¾¹ç¼˜å¤æ‚åº¦ã€åŒºåŸŸé¢ç§¯å’Œçº¹ç†ç‰¹å¾ï¼Œè‡ªåŠ¨æ‹Ÿåˆé˜ˆå€¼ï¼Œç»˜åˆ¶åˆ†å¸ƒå›¾
è¾“å‡ºï¼šJSONæ ¼å¼ã€å¯è¯»æ–‡æœ¬æ ¼å¼å’Œç®€æ´logæ ¼å¼çš„æŠ¥å‘Š
"""

import os
import cv2
import numpy as np
import json
from skimage.feature import graycomatrix, graycoprops
import matplotlib.pyplot as plt
from datetime import datetime

# ---------------------------- ç‰¹å¾è®¡ç®—éƒ¨åˆ† ----------------------------

def edge_complexity(mask):
    edges = cv2.Canny((mask * 255).astype(np.uint8), 100, 200)
    return int(np.sum(edges))

def instance_area(mask):
    return int(np.sum(mask))

def texture_complexity(mask, distances=[1], angles=[0]):
    mask_uint8 = (mask * 255).astype(np.uint8)
    glcm = graycomatrix(mask_uint8, distances=distances, angles=angles, symmetric=True, normed=True)
    contrast = float(graycoprops(glcm, 'contrast')[0, 0])
    homogeneity = float(graycoprops(glcm, 'homogeneity')[0, 0])
    energy = float(graycoprops(glcm, 'energy')[0, 0])
    glcm_norm = glcm / (glcm.sum() + 1e-10)
    entropy = -float(np.sum(glcm_norm * np.log(glcm_norm + 1e-10)))
    return contrast, homogeneity, energy, entropy

def calculate_complexity(mask):
    edge_len = edge_complexity(mask)
    area = instance_area(mask)
    contrast, homogeneity, energy, entropy = texture_complexity(mask)
    complexity_ratio = float(edge_len / area) if area > 0 else 0.0
    texture_score = float(contrast + homogeneity + energy + entropy)
    combined_score = complexity_ratio + texture_score
    return combined_score, complexity_ratio, area, edge_len, texture_score

# ---------------------------- æµå¼å¤„ç†éƒ¨åˆ† ----------------------------

def calculate_all_complexities_streaming(directory):
    complexities = {}
    all_scores = []

    for file in os.listdir(directory):
        if not file.lower().endswith('.png'):
            continue

        file_path = os.path.join(directory, file)
        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {file_path}")
            continue

        mask = (img / 255.0).astype(np.float32)

        try:
            combined_score, complexity_ratio, area, edge_len, texture_score = calculate_complexity(mask)
            complexities[file] = {
                "combined_score": combined_score,
                "complexity_ratio": complexity_ratio,
                "area": area,
                "edge_length": edge_len,
                "texture_score": texture_score
            }
            all_scores.append(combined_score)
        except Exception as e:
            print(f"âŒ å¤„ç† {file} æ—¶å‡ºé”™: {str(e)}")
            complexities[file] = None

    return complexities, all_scores

# ---------------------------- é˜ˆå€¼æ‹Ÿåˆ ----------------------------

def fit_thresholds(scores, low_percentile=33, high_percentile=66):
    low_th = np.percentile(scores, low_percentile)
    high_th = np.percentile(scores, high_percentile)
    return low_th, high_th

# ---------------------------- å¯è§†åŒ– ----------------------------

def plot_score_distribution(scores, low_th=None, high_th=None, bins=50, save_path=None):
    plt.figure(figsize=(10, 6))
    plt.hist(scores, bins=bins, color='skyblue', edgecolor='black')
    if low_th is not None:
        plt.axvline(x=low_th, color='green', linestyle='--', label=f'Low Threshold: {low_th:.2f}')
    if high_th is not None:
        plt.axvline(x=high_th, color='red', linestyle='--', label=f'High Threshold: {high_th:.2f}')
    plt.xlabel("Complexity Score")
    plt.ylabel("Instance Count")
    plt.title("Instance Complexity Score Distribution")
    plt.legend()
    plt.grid(True)
    if save_path:
        plt.savefig(save_path)
        print(f"ğŸ“Š å¤æ‚åº¦åˆ†å¸ƒå›¾ä¿å­˜è‡³: {save_path}")
    else:
        plt.show()

# ---------------------------- ä¿å­˜ ----------------------------

def save_complexities_to_json(complexities, output_file):
    def type_converter(obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, dict):
            return {k: type_converter(v) for k, v in obj.items()}
        if isinstance(obj, (list, tuple)):
            return [type_converter(x) for x in obj]
        return obj

    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(type_converter(complexities), f, indent=4, ensure_ascii=False)

def save_complexities_to_txt(complexities, output_file):
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=== å›¾åƒå¤æ‚åº¦åˆ†ææŠ¥å‘Š ===\n\n")
        for file, metrics in complexities.items():
            if not metrics:
                f.write(f"{file}: è®¡ç®—å¤±è´¥\n\n")
                continue
            f.write(f"{file}:\n")
            f.write(f"  â€¢ ç»¼åˆå¤æ‚åº¦åˆ†æ•°: {metrics['combined_score']:.4f}\n")
            f.write(f"  â€¢ å¤æ‚åº¦æ¯”å€¼: {metrics['complexity_ratio']:.4f}\n")
            f.write(f"  â€¢ åŒºåŸŸé¢ç§¯: {metrics['area']} åƒç´ \n")
            f.write(f"  â€¢ è¾¹ç¼˜é•¿åº¦: {metrics['edge_length']} åƒç´ \n")
            f.write(f"  â€¢ çº¹ç†å¾—åˆ†: {metrics['texture_score']:.4f}\n\n")

def save_simple_log(complexities, output_file):
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        for file, metrics in complexities.items():
            if not metrics:
                continue
            now = datetime.now().strftime("%y-%m-%d %H:%M:%S.%f")[:-3]
            line = f"{now} - INFO: {file} - complexity: {metrics['combined_score']:.6f}\n"
            f.write(line)

# ---------------------------- ä¸»ç¨‹åº ----------------------------

if __name__ == "__main__":
    INPUT_DIR = '/home/ruiyang/FRY/ultralytics/output/DIV2K_valid_HR'
    JSON_OUTPUT = '/home/ruiyang/FRY/ultralytics/output/metrics/complexities.json'
    TXT_OUTPUT = '/home/ruiyang/FRY/ultralytics/output/metrics/complexities.txt'
    SIMPLE_LOG_OUTPUT = '/home/ruiyang/FRY/ultralytics/output/metrics/complexity_simple.log'
    PLOT_OUTPUT = '/home/ruiyang/FRY/ultralytics/output/metrics/complexity_distribution.png'

    print("ğŸŸ¢ å›¾åƒå¤æ‚åº¦åˆ†æå¼€å§‹...")

    # 1. æµå¼å¤„ç†è®¡ç®—
    print("âŠ æ­£åœ¨æµå¼å¤„ç†è®¡ç®—å›¾åƒ...")
    complexities, all_scores = calculate_all_complexities_streaming(INPUT_DIR)
    if len(all_scores) == 0:
        print("âŒ é”™è¯¯ï¼šæœªè®¡ç®—åˆ°ä»»ä½•å¤æ‚åº¦åˆ†æ•°ï¼")
        exit(1)

    # 2. é˜ˆå€¼æ‹Ÿåˆ
    print("â‹ è‡ªåŠ¨æ‹Ÿåˆå¤æ‚åº¦é˜ˆå€¼...")
    low_th, high_th = fit_thresholds(all_scores)
    print(f"âœ… æ‹Ÿåˆé˜ˆå€¼ï¼šä½é˜ˆå€¼ = {low_th:.4f}, é«˜é˜ˆå€¼ = {high_th:.4f}")

    # 3. ä¿å­˜ç»“æœ
    print("âŒ æ­£åœ¨ä¿å­˜ç»“æœ...")
    save_complexities_to_json(complexities, JSON_OUTPUT)
    save_complexities_to_txt(complexities, TXT_OUTPUT)
    save_simple_log(complexities, SIMPLE_LOG_OUTPUT)

    # 4. å¯è§†åŒ–
    print("â æ­£åœ¨ç»˜åˆ¶å¤æ‚åº¦åˆ†å¸ƒå›¾...")
    plot_score_distribution(all_scores, low_th=low_th, high_th=high_th, save_path=PLOT_OUTPUT)

    print(f"""\nâœ… åˆ†æå®Œæˆï¼
JSONæŠ¥å‘Š: {JSON_OUTPUT}
æ–‡æœ¬æŠ¥å‘Š: {TXT_OUTPUT}
ç®€å•LOG: {SIMPLE_LOG_OUTPUT}
åˆ†å¸ƒå›¾: {PLOT_OUTPUT}
é˜ˆå€¼: ä½é˜ˆå€¼={low_th:.4f}, é«˜é˜ˆå€¼={high_th:.4f}
å®ä¾‹å¤æ‚åº¦åˆ†æ•°æ•°é‡: {len(all_scores)}
""")
